\documentclass[12pt]{article}
\input{presets/wang/input.tex}
\input{presets/misc.tex}
\input{presets/julia_lstlisting.tex}

% === TEMPLATE HOW TO USE ======
% To begine here is a list of things: 
% [ ]: Change title. 
% [ ]: Fill into the author names, affiliation and contact info. 
% [ ]: Fill in the abstract. 
% [ ]: Fill/change in AMS mathematics subject classification code, and the keywords. 

\begin{document}

\title{
    {
        \fontfamily{ptm}\selectfont 
        First Order Nonsmooth Optimization: 
        Algorithm Design, Analysis, Convergence, and Applications
    }
    }

\author{
    \thanks{Department of Mathematics, I.K. Barber Faculty of Science,
    The University of British Columbia, Kelowna, BC Canada V1V 1V7. 
    E-mail:  \texttt{alto@mail.ubc.ca}.}~Hongda Li
    % \thanks{Department of Mathematics, I.K. Barber Faculty of Science,
    % The University of British Columbia, Kelowna, BC Canada V1V 1V7. 
    % E-mail:  \texttt{shawn.wang@ubc.ca}.}~ and~Author Name 2
}

\date{\today}

\maketitle

% \vskip 8mm

\begin{abstract} 
    \noindent
    The research proposal focuses on the theories and practice in solving nonsmooth optimization. 
    The theme of proposal highlight topics of interests that emphasize the computations and applications aspect of algorithms that exhibits both practical and theoretical importance. 
    We summarize our ongoing research in unifying Nesterov type accelerated proximal gradient method and proposes our Free R-WAPG method. 
    We survey literatures under the topic of Catalyst Meta Acceleration framework used in accelerating variance reduced methods in the settings of Data Science and Machine Learning. 
    Furthermore, we present literatures and progress in topics such as Performance Estimation Problem, Inexact Proximal Point, acceleration without convexity. 
    At the end there is a section summarizing a method we developed for tree species classifications using Sentinel-2 satellite remote sensing data using big data analytics by extract spectral signatures of ground vegetation covers. 


\end{abstract}
% \noindent{\bfseries 2010 Mathematics Subject Classification:}
% Primary 65K10, 90c25, 90C30; Secondary 65Y20. 
% \noindent{\bfseries Keywords: } Non-convex Optimizations, Proximal Point. 

\newpage
\tableofcontents

\section{Introduction}
    Let $\RR^n$ be the ambient space. We consider 
    \begin{align}
        \min_{x \in \RR^n} \left\lbrace
            F(x): f(x) + g(x)
        \right\rbrace.
    \end{align}\label{eqn:additive-comp-obj}
    Unless specified, assume $f$ is a smooth function with $L$-Lipschitz gradient operator. 
    Unless specified, assume $g$ is a convex function. 
    In the literatures this type of problems are referred to as additive composite problems. 

    \par
    Our ongoing research concerns accelerated proximal gradient type method for solving (\ref{eqn:additive-comp-obj}). 
    In the expository writing by Walkington \cite{noel_nesterovs_nodate}, a variant for of accelerated gradient method for strongly convex function $f$ is discussed. 
    We had two lingering questions after reading it. 
    \begin{enumerate}
        \item Do there exist a unified description for the convergence for both variants of the algorithm. 
        \item Is it possible to attain faster convergence rate without knowledge about the strong convexity of function $f$. 
    \end{enumerate}
    The good news is we have definitive answers for both questions through our own efforts of research. 
    Section \ref{sec:unify-nes-acceleration}, \ref{sec:spectral-momentum} are our ongoing research which present the answers to the questions. 
    \par
    In Section \ref{sec:unify-nes-acceleration}, we proposed the method of ``Relaxed Weak Accelerated Proximal Gradient (R-WAPG)'' as the foundation to describe several variants of Accelerated proximal gradient method in the literatures. 
    The convergence theories of R-WAPG allows us to model convergence of accelerated proximal gradient method where the momentum sequence doesn't strictly follow the conditions presented in the literatures. 
    The descriptive power of R-WAPG allows convergence analysis for all the variants using one single theorem. 
    \par
    In Section \ref{sec:spectral-momentum} we propose a practical algorithm that exploits a specific term in the proof of R-WAPG to achieve faster convergence for solving (\ref{eqn:additive-comp-obj}) without knowing parameter $L, \mu$ in prior. 
    Results of numerical experiments are presented. 
    \par
    Section \ref{sec:catalyst} are results of literatures review in MATH 590. 
    It's based on a series of papers (CITATION HERE) in the topic of Catalyst Meta Acceleration method for First Order Variance Reduced Methods. 
    We will point out potential future direction of research of Catalyst acceleration. 
    \par
    Section \ref{sec:pep}, \ref{sec:inexact-prox}, \ref{sec:nes-acc-ncnvx} preview literatures in  nonsmooth optimization frontier research where progress and impacts can be made.  





    
\section{Preliminaries}
    Beck's book \cite{beck_first-order_2017}. 
    \subsection{Fundamentals in convex analysis}
    \subsection{Fundamentals in non-convex analysis}

\section{Unifying variants of Nesterov's accelerated methods}\label{sec:unify-nes-acceleration}
    

\section{Method Free R-WAPG}\label{sec:spectral-momentum}

\section{Catalyst accelerations and future works}\label{sec:catalyst}

\section{Performance estimation problems}\label{sec:pep}

\section{Methods of inexact proximal point}\label{sec:inexact-prox}

\section{Nestrov's acceleration in the non-convex case and momentum in general}\label{sec:nes-acc-ncnvx}

\section{Using PostGreSQL and big data analytic method for species classification on Sentinel-2 Satellite remote sensing imagery}


\bibliographystyle{siam}
\bibliography{references/proposal.bib}
\newpage

\appendix

\end{document}
