\documentclass[12pt]{article}

% \input{presets/wang_full.tex}
\usepackage{ifthen}\newboolean{draftmode}\setboolean{draftmode}{true}
\input{presets/wang/input.tex}
\input{presets/misc.tex}
\input{presets/julia_lstlisting.tex}

% NOTATIONS FOR THIS PAPER 
\DeclareMathOperator{\dist}{\mathop{dist}}
\DeclareMathOperator{\rng}{\mathop{rng}}



\title{{\fontfamily{ptm}\selectfont Inexect Accelerated Proximal Gradient }}

\author{
    Author 1 Name, Author 2 Name
    \thanks{
        Subject type, Some Department of Some University, Location of the University,
        Country. E-mail: \texttt{author.namee@university.edu}.
    }
}

\begin{document}

% TITLE, ABSTRACT ==============================================================
\date{\today}
\maketitle
\todoinline{This paper is currently in draft mode. Check source to change options. }
\begin{abstract} 
    \noindent
    This is still a draft. \cite{zhang_robust_2022}. 
\end{abstract}
\noindent{\bfseries 2010 Mathematics Subject Classification:}
Primary 47H05, 52A41, 90C25; Secondary 15A09, 26A51, 26B25, 26E60, 47H09, 47A63.
\noindent{\bfseries Keywords:}

\section{Introduction}
    \textbf{Notations.}
    Let $g: \RR^n \rightarrow\overline \RR$, we denote $g^\star$ to be the Fenchel conjugate. 
    $I: \RR^n \rightarrow \RR^n$ denotes the identity operator.
    For a multivalued mapping $T: \RR^n \rightarrow 2^{\RR^n}$, $\gra T$ denotes the graph of the operator, defined as $\{(x, y)\in \RR^n \times \RR^n : y \in Tx\}$. 
    \subsection{Epsilon subgradient and inexact proximal point}
        \begin{definition}[epsilon subgradient]\label{def:esp-subgrad}
            Let $g: \RR^n \rightarrow \overline \RR$ be proper, lsc. 
            Let $\epsilon \ge 0$. 
            Then the $\epsilon$-subgradient of $g$ at some $\bar x \in \dom g$ is given by: 
            $$
            \begin{aligned}
                \partial g_\epsilon(\bar  x) := 
                \left\lbrace
                    v \in \RR^n \left| \; 
                        \langle v, x - \bar  x\rangle \le 
                        g(x) - g(\bar x) + \epsilon \;\forall x \in \RR^n
                    \right. 
                \right\rbrace.
            \end{aligned}
            $$
            When $\bar x \not \in \dom g$, it has $\partial g_\epsilon(\bar x) = \emptyset$. 
        \end{definition}
        \begin{remark}
            $\partial_\epsilon g$ is a multivalued operator and, it's not monotone, unless $\epsilon = 0$, which makes it equivalent to French subgradient $\partial g$. 
        \end{remark}
        If we assume lsc, proper and convex $g$, we will now introduce results in the literatures that we will use. 
        \begin{fact}[epsilon Fenchel inequality]\label{fact:esp-fenchel-ineq}
            Let $\epsilon \ge 0$, then:
            \begin{align*}
                x^* \in \partial_\epsilon f(\bar x)\iff f^\star(x^*) + f(\bar x) \le \langle x^*, \bar x\rangle + \epsilon \implies \bar x \in \partial_\epsilon f^\star(x^*).
            \end{align*}
            They are all equivalent if $f^{\star\star}(\bar x) = f(\bar x)$. 
        \end{fact}
        \begin{remark}
            The above fact is taken from Zalinascu \cite[Theorem 2.4.2]{zalinescu_convex_2002}. 
        \end{remark}
        % \begin{fact}[strong epsilon subgradient sum rule]\label{fact:esp-subgrad-sum-rule}
        %     Take both $f, g: \RR^n\rightarrow \overline \RR$. 
        %     Let $\epsilon \ge 0$. 
        %     Then the epsilon subgradient sum rule states that 
        %     \begin{align*}
        %         \partial_\epsilon[f + g](\bar x) = 
        %         \bigcup \left\lbrace
        %             \partial_{\epsilon_1} f(\bar x) + 
        %             \partial_{\epsilon_2} g(\bar x) \left|\; 
        %                 \min(\epsilon_1, \epsilon_2) \ge 0\wedge 
        %                 \epsilon_1 + \epsilon_2 = \epsilon
        %             \right.
        %         \right\rbrace
        %     \end{align*}
        %     Under the scenario that: $\reli\dom f \cap \reli\dom g \neq \emptyset$. 
        % \end{fact}
        % \begin{remark}
        %     The above is taken from Morduchovich, Mau Nam \cite[Theorem 5.19]{mordukhovich_convex_2022}. 
        % \end{remark}
        We will now define inexact proximal point based on epsilon subgradient
        \begin{definition}[inexact proximal point]
            For all $x \in \RR^n, \epsilon \ge 0, \lambda > 0$, $\tilde x$ is an inexact evaluation of proximal point at $x$, if and only if it satisfies: 
            \begin{align*}
                \lambda^{-1}(x - \tilde x) \in \partial_{\epsilon} g(\tilde x). 
            \end{align*}
            We denote it by $\tilde x \approx_\epsilon \hprox_{\lambda g}(x)$. 
        \end{definition}
        \begin{remark}
            This definition is nothing new, for example see Villa et al. \cite[Definition 2.1]{villa_accelerated_2013}
        \end{remark}
        \begin{fact}[the resolvant identity]\label{fact:resv-identity}
            Let $T: \RR^n \rightarrow 2^{\RR^n}$, then it has: 
            \begin{align*}
                (I + T)^{-1} = (I - (I + T^{-1})^{-1}).
            \end{align*}
        \end{fact}
        \begin{theorem}[inexact Moreau decomposition]
            Let $g: \RR^n \rightarrow \overline \RR$ be a closed, convex and proper function. 
            It has the equivalence
            \begin{align*}
                \tilde y \approx_\epsilon \hprox_{\lambda^{-1}g^\star}(\lambda^{-1}y)
                \iff 
                y - \lambda \tilde y \approx_\epsilon \hprox_{\lambda g}(y). 
            \end{align*}
        \end{theorem}
        \begin{proof}
            Consider $\tilde y \approx_\epsilon \hprox_{\lambda^{-1}g^\star}(\lambda^{-1}y)$, then it has: 
            \begin{align*}
                & 
                \tilde y 
                \in (I + \lambda^{-1}\partial_\epsilon g^\star)^{-1}(\lambda^{-1}y)
                \\
                \iff &
                (\lambda^{-1}y, \tilde y)\in 
                \gra(I + \lambda^{-1}\partial_\epsilon g^\star)^{-1}
                \\
                \underset{(1)}{\iff} &
                (\lambda^{-1}y, \tilde y)\in 
                \gra(I - (I + \partial_\epsilon g\circ(\lambda I))^{-1})
                \\
                \iff &
                (\lambda^{-1}y, \lambda^{-1}y - \tilde y)\in 
                \gra(I + \partial_\epsilon g\circ(\lambda I))^{-1}
                \\
                \iff &
                (\lambda^{-1}y - \tilde y, \lambda^{-1}y)\in 
                \gra(I + \partial_\epsilon g\circ(\lambda I))
                \\
                \iff &
                (y - \lambda\tilde y, \lambda^{-1}y)\in 
                \gra(\lambda^{-1}I + \partial_\epsilon g)
                \\
                \iff &
                (y - \lambda\tilde y, y)\in 
                \gra(I + \lambda\partial_\epsilon g)
                \\
                \iff& 
                y - \lambda \tilde y \in 
                (I + \lambda \partial_\epsilon g)^{-1}y
                \\
                \iff& 
                y - \lambda \tilde y \approx_\epsilon \hprox_{\lambda g}(y). 
            \end{align*}
            At (1) we can use Fact \ref{fact:resv-identity}, and it has $(\lambda^{-1}\partial_\epsilon g^\star)^{-1} = \partial_\epsilon g\circ(\lambda I)$ by Fact \ref{fact:esp-fenchel-ineq} and the assumption that $g$ is closed, convex and proper. 
        \end{proof}

    \subsection{Inexact proximal gradient inequality}
        \begin{assumption}[for inexact proximal gradient]\label{ass:for-inxt-pg-ineq}
            The assumption is about $(f, g, L)$. 
            We assume that 
            \begin{enumerate}[nosep]
                \item $f: \RR^n \rightarrow \RR$ is a convex, $L$ Lipschitz function. 
                \item $g: \RR^n \rightarrow \overline\RR$ is a convex, proper, and lsc function which we do not have its exact proximal operator. 
            \end{enumerate}
        \end{assumption}
        We develop the theory based on the use of epsilon subgradient as in Definition \ref{def:esp-subgrad}. 
        \begin{definition}[inexact proximal gradient]\label{def:inxt-pg}
            Let $(f, g, L)$ satisfies Assumption \ref{ass:for-inxt-pg-ineq}. 
            Let $\epsilon \ge 0, B \ge 0$. 
            Then, $\tilde x \approx_\epsilon T_B(x)$ is an inexact proximal gradient if it satisfies variational inequality: 
            \begin{align*}
                \mathbf 0 \in \nabla f(x) + B(x - \tilde x) + \partial_{\epsilon} g(\tilde x). 
            \end{align*}
        \end{definition}
        \begin{remark}
            We assumed that we can get exact evaluation of $\nabla f$ at any points $x \in \RR^n$. 
        \end{remark}
        \begin{lemma}[other representations of inexact proximal gradient]\;\\
            Let $(f, g, L)$ satisfies Assumption \ref{ass:for-inxt-pg-ineq}.
            Let $\epsilon \ge 0, B \ge 0$, then for all $x \approx_\epsilon T_B(x)$, it has the following equivalent representations: 
            \begin{align*}
                & (x - B^{-1}\nabla f(x)) - \tilde x 
                \in B^{-1} \partial_\epsilon g(\tilde x)
                \\
                \iff 
                & \tilde x \in (I + B^{-1}\partial_\epsilon g(\tilde x))^{-1}
                (x - B^{-1}\nabla f(x))
                \\
                \iff 
                & x \approx_\epsilon \hprox_{B^{-1} g}
                \left(x - B^{-1}\nabla f(x)\right)
            \end{align*}
        \end{lemma}
        \begin{proof}
            It's direct. 
        \end{proof}
        \begin{theorem}[inexact over-regularized proximal gradient inequality]\;\label{thm:inxt-pg-ineq}\\
            Let $(f, g, L)$ satisfies Assumption \ref{ass:for-inxt-pg-ineq} . 
            Let $\epsilon \ge 0$. 
            Consider $\tilde x \approx_\epsilon T_{B + \beta}(x)$. 
            If in addition, it satisfies $D_f(\tilde x, x) \le B/2\Vert x - \tilde x\Vert^2$, then it has $\forall z \in \RR^n$: 
            \begin{align*}
                - \epsilon &\le 
                F(z) - F(\tilde x)
                + \frac{B + \beta}{2}\Vert x - z\Vert^2
                - \frac{B + \beta}{2}\Vert z - \tilde x\Vert^2
                - \frac{\beta}{2}\Vert \tilde x - x\Vert^2. 
            \end{align*}
        \end{theorem}
        \begin{proof}
            By Definition \ref{def:inxt-pg} write the variational inequality that describes $\tilde x \approx_\epsilon T_B(x)$, and the definition of epsilon subgradient (Definition \ref{def:esp-subgrad}) it has for all $z \in \RR^n$: 
            \begin{align*}
                - \epsilon &\le 
                g(z) - g(\tilde x) - \langle (B + \beta)(\tilde x - x) - \nabla f(x), z - \tilde x\rangle
                \\
                &= 
                g(z) - g(\tilde x) 
                - (B + \beta)\langle \tilde x - x, z - \tilde x\rangle
                + \langle \nabla f(x), z - \tilde x\rangle
                \\
                &\underset{(1)}{\le} 
                g(z) + f(z) - g(\tilde x) - f(\tilde x)
                - (B + \beta)\langle \tilde x - x, z - \tilde x\rangle
                - D_f(z, x) + D_f(\tilde x, x)
                \\
                &\underset{(2)}{\le} 
                F(z) - F(\tilde x)
                - (B + \beta)\langle \tilde x - x, z - \tilde x\rangle
                + \frac{B}{2}\Vert \tilde x - x\Vert^2
                \\
                &=
                F(z) - F(\tilde x) + \frac{B + \beta}{2}\left(
                    \Vert x - z\Vert^2
                    - \Vert \tilde x - x\Vert^2
                    - \Vert z - \tilde x\Vert^2
                \right)
                + \frac{B}{2}\Vert \tilde x - x\Vert^2
                \\
                &= 
                F(z) - F(\tilde x)
                + \frac{B + \beta}{2}\Vert x - z\Vert^2
                - \frac{B + \beta}{2}\Vert z - \tilde x\Vert^2
                - \frac{\beta}{2}\Vert \tilde x - x\Vert^2. 
            \end{align*}
            At (1), we used considered the following: 
            \begin{align*}
                \langle \nabla f(x), z - x\rangle &= \langle \nabla f(x), z - x + x - \tilde x\rangle
                \\
                &= \langle \nabla f(x), z - x\rangle + \langle \nabla f(x), x - \tilde x\rangle
                \\
                &= -D_f(z, x) + f(z) - f(x) + D_f(\tilde x, x) - f(\tilde x) + f(x)
                \\
                &= -D_f(z, x) + f(z) + D_f(\tilde x, x) - f(\tilde x). 
            \end{align*}
            At (2), we used the fact that $f$ is convex hence $- D_f(z, x) \le 0$ always, and in the statement hypothesis we assumed that $B$ has $D_f(\tilde x, x) \le B/2\Vert \tilde x - x\Vert^2$. 
        \end{proof}
    \subsection{optimizing the inexact proximal point problem}
        In this section we will show an optimization problem that allows us to solve for some $\tilde x \approx_\epsilon \hprox_{\lambda g}(z)$. 
        Most of these results are from the literature. 
        To start, we must assume the following about a function $g: \RR^n \rightarrow \overline \RR$, with $g$ closed, convex and proper. 
        \begin{assumption}[for inexact proximal operator]\;\label{ass:for-inxt-prox}\\
            This assumption is about $(g, \omega, A)$. 
            Let $m \in \N, n \in \RR^n$, we assume that 
            \begin{enumerate}[nosep]
                \item $A\in \RR^{m \times n}$ is a matrix. 
                \item $\omega: \RR^n \rightarrow \overline \RR$ is a closed and convex function such that it admits proximal operator $\hprox_{\lambda\omega}$ and, its conjugate $\omega^\star$ is known. 
                \item $g := \omega(Ax)$ such that $\rng A \cap \reli\dom g \neq\emptyset$. 
            \end{enumerate}
        \end{assumption}
        Now, we are ready to discuss how to choose $\tilde x \approx_\epsilon \hprox_{\lambda g}(x)$. 
        Fix $y \in \RR^n, \lambda > 0$, we are ultimately interested in minimizing: 
        \begin{align}
            \Phi_\lambda(u) &:= \omega(Au) + \frac{1}{2\lambda} \Vert u - y\Vert^2
        \end{align}
        This problem admits dual objective in $\RR^m$: 
        \begin{align}
            \Psi_\lambda(v) &:=
            \frac{1}{2\lambda}\Vert \lambda A^\top v - y\Vert^2
            + \omega^\star(v) - \frac{1}{2\lambda}\Vert y\Vert^2. 
        \end{align}
        We define the duality gap
        \begin{align}
            \mathbf G_\lambda(u, v) &:= \Phi_\lambda(u) + \Psi_\lambda(v). 
        \end{align}
        If strong duality holds, it exists $(\hat u, \hat v)$ such that we have the following: 
        \begin{align*}
            \mathbf G_\lambda(\hat u, \hat v) = 0 = \min_{u} \Phi_\lambda(u) + \min_v \Psi_\lambda(v)
        \end{align*}
        The following theorem quantifies a sufficient conditions for $\tilde x \approx_\epsilon \hprox_{\lambda g}(x)$. 
        The theorem below is from \cite[Proposition 2.2]{villa_accelerated_2013}. 
        \begin{theorem}[primal translate to dual]\label{thm:primal-dual-trans}
            Let $\epsilon \ge 0$, $g:\RR^n \rightarrow \overline \RR$ be convex, proper and closed then 
            \begin{align*}
                \left(
                    \forall z \approx_\epsilon \hprox_{\lambda g}(y) 
                \right)(\exists v \in \dom \omega^\star): z = y - \lambda B^\top v. 
            \end{align*}
        \end{theorem}
        The theorem is from Villa et al. \cite[Proposition 2.3]{villa_accelerated_2013}
        \begin{theorem}[duality gap of inexact proximal problem]\label{thm:dlty-gap-inxt-pp}
            For all $\epsilon \ge 0$, $v \in \RR^n$. 
            Consider conditions 
            \begin{enumerate}[nosep]
                \item $\mathbf G_\lambda(y - \lambda B^\top v, v) \le \epsilon$. 
                \item $B^\top v \approx_\epsilon \hprox_{\lambda^{-1}g^\star}(\lambda^{-1}y)$. 
                \item $y - \lambda B^\top v \approx_{\epsilon} \hprox_{\lambda g}(y)$. 
            \end{enumerate}
            They have $(a)\implies (b) \iff (c)$. 
            If in addition $\omega^\star(v) = g^\star(B^\top v)$, then all three conditions are equivalent. 
        \end{theorem}
        Next, let's explore some options for minimizing the duality gap of the proximal problem. 
        \todoinline{
            STILL WRITING AND NOT FINISHED YET! 
        }


    \subsection{Literature reviews}
\bibliographystyle{siam}
\bibliography{references/refs.bib}
\end{document}