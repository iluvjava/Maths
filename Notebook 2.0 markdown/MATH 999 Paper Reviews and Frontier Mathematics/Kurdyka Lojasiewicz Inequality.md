
### **Intro**

Has something to do with how sharp a function is. Has something to do with the convergence of the gradient descend method and proximal point method. 

* Introductory materials for school of economic \<A User's Guide to the KL inequalities\>: [here](http://www.gipsa-lab.fr/summerschool/slra2015/BolteGrenoble.pdf). 
* Another one that discuss the concept under smooth gradient descend is: [here](https://regularize.wordpress.com/2013/09/25/the-kurdyka-lojasiewicz-inequality-and-gradient-descent-methods/), and it servers as an motivations for a certain context where KL, PL inequalities are useful. 
* \<Linear Convergence of Gradient and Proximal-Gradient Methods under the Polyak-Lojasiewicz Conditions\>: [here](https://arxiv.org/abs/1608.04636). 
* \<The exact Modulus of the Generalized Kurdyka-Lojasiewicz Property\>: [here](https://open.library.ubc.ca/media/stream/pdf/24/1.0392646/3). 
* A ppt presentation from university of waterloo, about the KL, PL inequalities under the context of Proximal methods: [here](https://angms.science/doc/NCVX/proxgradconv_proxPLiq.pdf). 