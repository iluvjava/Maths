- [Proximal Gradient, Forward Backwards Envelope](Proximal%20Gradient,%20Forward%20Backwards%20Envelope.md)
- [Proximal Gradient Convergence Rate](Proximal%20Gradient%20Convergence%20Rate.md)

---
### **Intro**

In this file, we show the weakest assumptions needed to derive a linear convergence rate of the proximal gradient method for smooth plus nonsmooth composite objective. 
We are following results from the paper: 
> [1] D. Drusvyatskiy and A. S. Lewis, “Error bounds, quadratic growth, and linear convergence of proximal methods,” June 27, 2016, arXiv: arXiv:1602.06661. doi: 10.48550/arXiv.1602.06661.

We note that, the linear convergence of just gradient descent, and proximal gradient can be very different. 

#### **Assumption 0 | Smooth and nonsmooth objective**
> The assumption is about $(f, g, F, L)$. 
> Assume that
> - $f: \R^n \rightarrow \R$ is a convex function with a $\beta$ Lipschitz smooth gradient. 
> - $g: \R^n \rightarrow \overline \R$ is a closed and convex function. 
> - The objective function $F = f + g$. 

#### **Definition | The proximal gradient method**
> Let $f$ be differentiable and $g: \R^n \rightarrow \overline \R$ be a closed, convex and proper function. 
> Let $t > 0$ be the stepsize. 
> An algorithm is a proximal gradient algorithm if it generates iterates $(x_k)_{k \ge 0}$ such it satisfies recurrence relation: 
> $$
> \begin{aligned}
>     x_{k + 1} = \prox_{t g}(x_t - t \nabla f(x_t)). 
> \end{aligned}
> $$

For all $(f, g, L)$ that satisfy **Assumptin 0**, Recall that we have gradient mapping opreator is defined to be: 

$$
\begin{aligned}
    \mathcal G_t(x) = t^{-1}(x - \prox_{tg}(x - t \nabla f(x))). 
\end{aligned}
$$

From the previous files, we were able to derive the proximal gradient inequality, stated by the following lemma: 

#### **Recall | The proximal gradient inequality**
> Let $(f, g, F, L)$ satisfies **Assumption 0**. 
> For all $x \in \R^n$ let $x^+ = \prox_{tg}(x - t \nabla f(x))$. 
> Then, it satisfies for all $z \in \R^n$ the inequaity: 
> $$
> \begin{aligned}
>     F(x^+) - F(z) &\le \langle \mathcal G_t(x), x - z\rangle - \frac{1}{2\beta}\Vert \mathcal G_t(x)\Vert^2. 
> \end{aligned}
> $$

**Proof**
See [Proximal Gradient Inequality Part I](Proximal%20Gradient%20Inequality%20Part%20I.md) for more. $\square$

#### **Recall | proximal gradient sufficient descent**
> Let $(f, g, F, L)$ satisfies **Assumption 0**. 
> Suppose that the sequence $(x_k)_{k \ge 0}$ is given by an algorithm that satisfes the **proximal gradient method**. 
> If, the stepsize has $t \le \beta^{-1}$, then it has sufficient descent conditions: 
> $$
> \begin{aligned}
>     F(x_{k}) - F(x_{k + 1}) \ge \frac{1}{2\beta} \Vert \mathcal G_t(x_k)\Vert^2. 
> \end{aligned}
> $$


---
### **Linear convergence rate of proximal gradient method**

The following assumptions characterize a sufficient conditions for linear convergence rate of the proximal gradient algorithm. 


#### **Assumption 1 | sufficient for linear convergence rate**
> The following assumption is about $(f, g, F, S, L, \gamma)$. 
> We assume the following. 
> - Suppose that $(f, g, F, L)$ satisfy **Assumption 0**. 
> - Assume that a set of minimizer $S$ exists for $F$. 
> - Assume that there exists $\gamma > 0$ such that for all $z \in \text{dom}\; F$, it satisfies $\gamma \Vert \mathcal G_t(x)\Vert \ge \dist(x | S)$. 


We compactify the linear convergence into the following claim. 

#### **Proposition | A linear convergence rate**
> Let $(F, g, F, S, L,\gamma)$ satisfies **Assumption 1**. 
> Let $\bar x \in S$, be arbitrary.
> Then, the iterates $(x_k)_{k \ge 0}$ generated by the **proximal gradient method** satisfies for all $k \ge 0$: 
> $$
> \begin{aligned}
>     F(x_{k + 1}) - F(\bar x)
>     &\le 
>     \left(
>         1 - \frac{1}{2\beta\gamma}
>     \right)(F(x_k) - F(\bar x)). 
> \end{aligned}
> $$

**Proof**

Denote $F^+$ to be the minimum value. 
From the proximal gradient inequality it has: 

$$
\begin{aligned}
    F(x_{k + 1}) - F^+ 
    &\le \Vert \mathcal G_t(x_k)\Vert \Vert x_k - \bar x\Vert 
    - \frac{1}{2\beta}\Vert \mathcal G(x_k)\Vert^2
    \\
    &= \Vert \mathcal G_t(x_k)\Vert^2\left(
        \frac{\Vert x_k - \bar x\Vert}{\Vert \mathcal G_t(x_k)\Vert}
        - \frac{1}{2\beta}
    \right)
    \\
    &\underset{(1)}{\le} 
    \Vert \mathcal G_t(x_k)\Vert^2\left(
        \gamma - \frac{1}{2\beta}
    \right). 
\end{aligned}
$$
At (1) we used the error bound conditions.
Assuming $\gamma - \frac{1}{2\beta} > 0$ （which is always true because the LHS of the above inequality is always $> 0$ when $\Vert \mathcal G_t(x_k)\Vert \ge 0$） it has 

$$
\begin{aligned}
    \frac{1}{2\beta}\left(
        \gamma - \frac{1}{2\beta}
    \right)^{-1}
    \left(F(x_{k + 1}) - F^+\right)
    &\le 
    \frac{1}{2\beta}\Vert \mathcal G_t(x_k)\Vert^2 
    \\
    &\underset{(1)}{\le} F(x_k) - F(x_{k + 1})
    \\
    &= F(x_k) - F^+ + F^+ - F(x_{k + 1}). 
\end{aligned}
$$

At (1), we used the descent inequality of proximal gradient algorithm, we can do that by the assumption that $t \le \beta^{-1}$. 
The coefficient simplifies by some algebra: 

$$
\begin{aligned}
    \frac{1}{2\beta}\left(
        \gamma - \frac{1}{2\beta}
    \right)^{-1}
    &= (2\beta \gamma - 1)^{-1}. 
\end{aligned}
$$

Move the $F^+ - F(x_{k + 1})$ term to the left it yields: 

$$
\begin{aligned}
    F(x_{k + 1}) - F^+ 
    &\le 
    \left(
        1 + (2\beta \gamma - 1)^{-1}
    \right)^{-1} (F(x_k) - F^+)
    \\
    &= 
    \left(
        \frac{2\beta\gamma}{2\beta\gamma - 1}    
    \right)^{-1} (F(x_k) - F^+)
    \\
    &\le 
    \left(
        1 - \frac{1}{2\beta\gamma}
    \right)(F(x_k) - F^+). 
\end{aligned}
$$

And, the above inequality is sufficient for a linear convergence rate. 
$\square$

---
### **The strange condition proximal mapping error bound**

So, what is this strange condition we called error bound that we used here? 



