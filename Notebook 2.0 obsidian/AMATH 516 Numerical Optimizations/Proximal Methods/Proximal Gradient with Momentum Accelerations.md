[[Proximal Gradient Convergence Rate]]

---
### **Intro**

A thorough understanding of the Proximal Gradient without momentum is needed to understand this. This part of the text will make heavy references to Amir's Beck's book, and the paper [[FISTA_ A Fast Iterative Shrinka - Amir Beck.pdf]], and then the Presentation from L. Vanderberghe [here](https://www.seas.ucla.edu/~vandenbe/236C/lectures/fgrad.pdf)(Just for references materials here is not really taken from Vanderberghe's works) on Nesterov momentum method. In this excerpt, we will state the algorithm for the FISTA, and then we will attempt to prove the convergence rate while knowing the algorithm. And at the end we will try to discuss some of the magics behind sequence of numbers for the algorithm. 

**The FISTA Algorithm**

> let $L$ be the Lipschitz constant for the gradient of smooth function $g$, and then let the step size to be constant with $\beta^{-1}$, where $\beta \ge L$, $t_1 = 1$, initialize $y^{(0)} = x^{(0)}$. 
> 
> $$
> \begin{aligned}
>     x^{(k)} &= \text{prox}_{h, \beta^{-1}} (y^{(k)} + \beta^{-1}\nabla f(y^{(k)}))
>     \\
>     t_{k + 1} &= 
>     \frac{1 + \sqrt{1 + 4t_k^2}}{2}
>     \\
>     y^{(k + 1)} 
>     &=  x^{(k)} + \left(
>         \frac{t_k - 1}{t_{k + 1}}
>     \right)(x^{(k)} - x^{(k - 1)})
>     \\
>     k &= k + 1
> \end{aligned}
> $$

A line search algorithm will find the largest possible step size $\beta^{-1}$ such that $f(x^{(k + 1)})\le m_{x}(y|\beta)$. Where, we defined the upper bounding function modeled at point $x$ of $f$ and evaluated at point $y$ to be $m_x(y|L)$, where $L$ is the smoothness constant on the quadratic term of the function. 


The proof is non-trivial, and we take steps to build it up. We denotes $f = g + h$, where g is the $L$ strongly smooth function and $h$ is the convex function that is not necessarily smooth. 

**Theorem: Convergence Rate of FISTA**

Let $\bar x$ be one of the minimizer for the summed function $f$, then the convergence rate under the assumption that: 

* $g$ is strongly smooth with a constant, say $L_g$
* $h$ is convex, closed and proper. 
* $\text{ri}\circ \text{dom}(g)\cap \text{ri}\circ \text{dom}(g) \neq âˆ…$. 

> Let $x^{(k)}, y^{(k)}$  be the sequence generated by FISTA, then for any $k\ge 1$, we have: 
> 
> $$
> \begin{aligned}
>     f(x^{(k)}) - f(\bar x) \le 
>     \frac{2\alpha L_g\Vert x^{(0)} - \bar x\Vert^2}{(k + 1)^2}
> \end{aligned}
> $$
> 
> $\alpha = 1$ if the step size is constant, and when backtracking is used, then there exists a constant $\eta$ such that $\beta^{-1}_k\le L_g$ for all iteration number $k$, so that in the backtracking case, the constrant $\alpha = \eta$. 

**Remarks**

People don't think this is good enough and in Amir's textbook, and paper such as [this one](https://arxiv.org/abs/1811.01430), people augmented and improve the behavior of the original algorithm, so that it works better, faster, and greedier. 

---
### **First Lemma For the Proof**

**Lemma 1**

Let $y\in \mathbb R^{n}$ and $l > 0$, we define $\mathcal{P}_l^{g, h}(y) := \text{prox}_{h, l^{-1}}(y + l^{-1}\nabla g(y))$, and under certain context where there is no ambiguity we simply use $\mathcal{P}y$ instead, Here we let $l = L^{-1} \ge L_g$ where $L_g$ denotes the Lipschitz constant for the smooth function $g$. 

$$
\begin{aligned}
    f\circ \mathcal Py
    &\le 
    m_y(\mathcal{P}(y)|L)
    \\
    \implies f(x) - f\circ \mathcal Py
    &\ge 
    \frac{L}{2}\Vert \mathcal Py - y\Vert^2 + 
    L \langle y - x, \mathcal Py - y\rangle \quad 
    \forall x\in \mathbb R^n. 
\end{aligned}
$$

The proof was listed in the proof for the convergence rate for Proximal Gradient in the un-accelerated case (we extract out this particular lemma that pervious proof). Here, we just simplified the notations. This statement is listed as **Lemma 2.3** in \[Amir Beck and Marc Teboulle\]'s FISTA paper. 

---
### **The Second Lemma for the Proof**

> The fixed stepsize FISTA algorithm with a step size of $L$ asserts the following relations: 
> 
> $$
> \begin{aligned}
>     & 
>     \frac{2}{L}t^2_k \Delta_k - \frac{2}{L}t^2_{k + 1} \Delta_{k + 1} 
>     \ge 
>     \Vert u^{(k + 1)}\Vert^2 - \Vert u^{(k)}\Vert^2
>     \\
>     & \Delta_k := f(x^{(k)}) - f(\bar x)
>     \\
>     & u^{(k)} := t_k x^{(k)} - (t_k - 1)x^{(k - 1)} - \bar x,
> \end{aligned}
> $$
> and here, $\bar x$ denotes one of the minimizer for the function $f$. 

**Proof**

We invoke the first lemma with $x = x^{(k)}, y = y^{(k +1)}$ to give: 

$$
\begin{aligned}
    f(x^{(k)}) - f\circ \mathcal P y^{(k + 1)}
    & \ge 
    \frac{L}{2}\Vert \mathcal Py^{(k + 1)} - y^{(k + 1)}\Vert^2 + 
    L \langle y^{(k + 1)} - x^{(k)}, 
        \mathcal Py^{(k + 1)} - y^{(k + 1)}
    \rangle
    \\
    f(x^{(k)}) - f(x^{(k + 1)}) 
    & \ge 
    \frac{L}{2}\Vert x^{(k + 1)} - y^{(k + 1)}\Vert^2 + 
    L 
    \langle 
        y^{(k + 1)} - x^{(k)}, 
        x^{(k + 1)} - y^{(k + 1)}
    \rangle, 
    \\
    \implies
    2L^{-1} (\Delta_k - \Delta_{k + 1}) 
    & \ge 
    \Vert x^{(k + 1)} - y^{(k + 1)}\Vert^2 + 
    2\langle x^{(k + 1)} - y^{(k + 1)}, y^{(k + 1)} - x^{(k)}\rangle. 
\end{aligned}\tag{1}
$$

Observe that from the first line to the second line we invoke the definition for the updates for $x^{(k)}$ in the FISTA algorithm. We then invoke the lemma again with $x:= \bar x, y = y^{(k + 1)}$, and it gives us: 

$$
\begin{aligned}
    f(\bar x) - f\circ \mathcal P y^{(k + 1)}
    & \ge 
    \frac{L}{2}\Vert \mathcal P y^{(k + 1)} - y^{(k + 1)}\Vert^2 
    + L 
    \langle y^{(k + 1)} - \bar x, x^{(k + 1)} - y^{(k + 1)}\rangle
    \\
    f(\bar x) - f(x^{(k + 1)}) 
    &\ge 
    \frac{L}{2}\Vert x^{(k + 1)} - y^{(k + 1)}\Vert^2
    + 
    L \langle y^{(k + 1)} - \bar x, x^{(k + 1)} - y^{(k + 1)}\rangle
    \\
    -2L^{-1}\Delta_{k + 1}
    & \ge
    \Vert x^{(k + 1)} - y^{(k + 1)}\Vert^2
    + 
    2\langle y^{(k + 1)} - \bar x, x^{(k + 1)} - y^{(k + 1)}\rangle. 
\end{aligned}\tag{2}
$$

Consider the expression $(t_k - 1)(1) + (2)$, we obtain the LHS quantity: 

$$
\begin{aligned}
    &(t_{k + 1} - 1)L^{-1} (\Delta_k - \Delta_{k + 1}) 
    -
    2L^{-1}\Delta_{k + 1}
    \\
    = \; &
    2L^{-1}
    ((t_{k + 1} + 1)\Delta_k - (t_{k + 1} - 1)\Delta_{k + 1} - \Delta_{k + 1})
    \\
    = \; &
    2L^{-1}((t_{k + 1} - 1)\Delta_k - t_{k + 1}\Delta_{k + 1}), 
\end{aligned}\tag{3.LHS}
$$

and the RHS is: 

$$
\begin{aligned}
    & (t_{k + 1} - 1)\Vert x^{(k + 1)} - y^{(k + 1)}\Vert^2
    + 
    2(t_{k + 1} - 1)\langle y^{(k + 1)} - \bar x, x^{(k + 1)} - y^{(k + 1)}\rangle 
    \\
    & \quad 
    + \Vert x^{(k + 1)} - y^{(k + 1)}\Vert^2
    + 
    2\langle y^{(k + 1)} - \bar x, x^{(k + 1)} - y^{(k + 1)}\rangle
    \\
    = \; &
    t_{k + 1}\Vert x^{(k + 1)} - y^{(k + 1)}\Vert^2
    + 
    \langle 
        x^{(k + 1)} - y^{(k + 1)}, 
        \underbrace{2(t_{k + 1} - 1)(y^{(k + 1)} - x^{(k)}) + 2(y^{(k + 1)} - \bar x) }_
        {
            = 2(t_{k + 1}y^{(k + 1)} + (1 - t_{k + 1})x^{(k)} - \bar x)
        }
    \rangle
    \\
    = \; & 
    t_{k + 1}\Vert x^{(k + 1)} - y^{(k + 1)}\Vert^2
    + 
    2\langle 
        x^{(k + 1)} - y^{(k + 1)}, 
        t_{k + 1}y^{(k + 1)} + (1 - t_{k + 1})x^{(k)} - \bar x
    \rangle. 
\end{aligned}\tag{3.RHS}
$$

The entirety of expression (3) is given by: 

$$
\begin{aligned}
    & 2L^{-1}((t_{k + 1} - 1)\Delta_k - t_{k + 1}\Delta_{k + 1})
    \ge 
    t_{k + 1}\Vert x^{(k + 1)} - y^{(k + 1)}\Vert^2
    \\
    & \quad 
    + 
    2\langle 
        x^{(k + 1)} - y^{(k + 1)}, 
        t_{k + 1}y^{(k + 1)} + (1 - t_{k + 1})x^{(k)} - \bar x
    \rangle. 
\end{aligned}\tag{3}
$$

The next part of the proof shows some of the magics involves in changing the LHS,RHS of (3) to be the similar to what is in the theorem statement. It's accomplished by the relations for the sequence $t_k$, more specifically *it's hinged on the relations* $t_k^2 = t^2_{k + 1} - t_{k + 1}$ which is asserted by the FISTA algorithm. Using this fact we proceed by multiplying $t_{k + 1}$ on both sides of (3) and obtain: 

$$
\begin{aligned}
    & 2L^{-1}(\Delta_k t_k^2 - \Delta_{k + 1}t_{k + 1}^2)
    \\
    & \ge 
    \Vert t_{k + 1}(x^{(k + 1)} - y^{(k + 1)})\Vert^2 - 
    2\langle 
        t_{k + 1}(x^{(k + 1)} - y^{(k + 1)}), 
        t_{k + 1}y^{(k + 1)} - 
        (t_{k + 1} - 1)x^{(k)} - \bar x
    \rangle
    \\
    & 2L^{-1}(\Delta_k t_k^2 - \Delta_{k + 1}t_{k + 1}^2)
    \\ 
    & \ge 
    \Vert 
        \underbrace{t_{k + 1}x^{(k + 1)}}_{
            =:a
        } - \underbrace{t_{k + 1}y^{(k + 1)}}_{
            =:b
        }
    \Vert^2 
    - 
    2\langle 
       \underbrace{ t_{k + 1}x^{(k + 1)}}_{=:a} - t_{k + 1}y^{(k + 1)}, 
        \underbrace{t_{k + 1}y^{(k + 1)}}_{=:b} - 
        \underbrace{((t_{k + 1} - 1)x^{(k)} + \bar x)}_{=:c}
    \rangle
    \\
    & \ge 
    \Vert a - b\Vert^2 + 2\langle a - b, b -c\rangle
    \\
    & = 
    \Vert a - b\Vert^2 + \Vert b - c\Vert^2 + 
    2\langle a-b, b -c\rangle - \Vert b - c\Vert^2
    \\
    &= 
    \Vert a - c\Vert^2 - \Vert b - c\Vert^2
    \\
    &\ge 
    \Vert 
        t_{k+ 1}x^{(k + 1)} - 
        (t_{k + 1} - 1)x_k - \bar x 
    \Vert^2 - 
    \Vert 
        (t_{k + 1} - 1)x^{(k)} - t_{k + 1}y^{(k + 1)}
        - \bar x
    \Vert^2, 
\end{aligned}
$$

to prove the lemma, we need to match the form in the above 2 norm of the vector, we accomplish this by considering FISTA algorithm: 

$$
\begin{aligned}
    t_{k + 1}y^{(k + 1)} &= t_{k + 1}x^{(k)} + (t_k - 1)(x^{(k)} - x^{(k - 1)})
    \\
    t_{k + 1}y^{(k + 1)} - (t_{k + 1}- 1)x^{(k)}
    &= t_{k + 1}x^{(k)} - (t_{k + 1}- 1)x^{(k)} + (t_k - 1)(x^{(k)} - x^{(k - 1)})
    \\
    &= 
    x^{(k)} + (t_k - 1)x^{(k)} - (t_k - 1)x^{(k - 1)}
    \\
    &= t_kx^{(k)} - (t_k - 1)x^{(k - 1)}, 
\end{aligned}
$$

cf from previously we have: 

$$
\begin{aligned}
    & 2L^{-1}(\Delta_k t_k^2 - \Delta_{k + 1}t_{k + 1}^2)
    \\
    &\ge 
    \Vert 
        t_{k + 1}x^{(k + 1)}
        + 
        (1 - t_{k + 1}) x^{(k)} - \bar x
    \Vert^2
    - 
    \Vert t_kx^{(k)} + (1 - t_k)x^{(k -1)} - \bar x\Vert^2
    \\
    & \ge \Vert u^{(k + 1)}\Vert^2 - \Vert u^{(k)}\Vert^2. 
\end{aligned}
$$

And that completes the proof of the Second Lemma. 

**Remarks**

There should be some point, where we can infer the properties of the sequence $t_k$ instead of taking the sequence from FISTA algorithm for granted, there should also be a way to make a different decision during the proof so that this becomes the proof for the algorithm without the accelerations technique. 

---
### **Other Misc Lemmas**

**Lemma: The Third One**

> Let $\{a, b\}$ be positive real numbers sequence satisfying: $a_k - a_{k - 1}\ge b_{k + 1} - b_k, \forall k \ge 1$, with $a_1 + b_1 \le c, c > 0$, and then it would mean that $a_{k + 1}\le c$. 

The base case of the proof is obvious by the fact that $b_1$ is positive, hence $a_1 \le c$ is true. the relation automatically holds true for all $k\ge 1$ because $a_k - a_{k + 1}\ge b_{k + 1} - b_k \implies a_k + b_k \le c$, then $a_k - a_{k + 1}\ge b_{k + 1} - b_k \implies a_k + b_k \le a_{k + 1} + b_{k + 1} \implies a_{k + 1} + b_{k + 1} \le c\implies a_{k + 1}\le c$. 

**Remarks**:

*You should be pointing out the fact on where this lemma is useful for the convergence proof that comes later*. 

**Lemma: The Fourth One**

> The FISTA asserts $t_k \ge (k + 1)/2, \forall k \ge 1$. 

Using the update formula from FISTA, this obviously holds true in the case of $k = 1, t_1 = 1$, and it's not hard to see that if for some $k$ it's true then it's true for $k + 1$ because: 

$$
\begin{align*}
    t_k 
    &\ge \frac{k + 1}{2}
    \\
    4t_k^2 
    &\ge 4\left(
        \frac{k + 1}{2}
    \right)^2
    \\
    \implies 
    t_k &= \frac{1}{2}\left(
        1 + \sqrt{1 + 4t_k^2}
    \right)
    \\
    &= 
    \frac{1}{2} + \frac{\sqrt{1 + (k + 1)^2}}{2}
    \\
    & \ge \frac{1 + k}{2}, 
\end{align*}
$$

because $\sqrt{1 + (k + 1)^2} \ge k$. 


---
### **Completing the Proof**

Firstly we define the quantities: 
1. $a_k := (2/L)t_k^2 \Delta_k$.
2. $b_k := \Vert u^{(k)}\Vert^2$.
3. $c:= \Vert x^{(0)} - \bar x\Vert^2 = \Vert y^{(1)} - \bar x\Vert^2$. 

So  that the third lemma and the second lemma becomes relevant. Recall from the first lemma that: 

$$
\begin{aligned}
    2L^{-1}(\Delta_kt_k^2 - \Delta_{t + 1}t_{k + 1}^2) 
    &\ge 
    \Vert u^{(k + 1)}\Vert^2 - \Vert u^{(k)}\Vert^2
    \\
    a_k - a_{k + 1} &\ge 
    b_{k + 1} - b_k, 
\end{aligned}
$$

to invoke the third lemma, we consider the base case, which is true because using the first lemma: 

$$
\begin{aligned}
    f(\bar x) - f(x^{(1)}) &= 
    f(\bar x) - f(x^{(1)}) 
    \\
    \Delta_1& \ge 
    \frac{L}{2}\Vert \mathcal Py^{(1)} - y^{(1)}\Vert^2 + L 
    \langle y^{(1)} - \bar x, \mathcal P y^{(1)} - y^{(1)}\rangle
    \\
    & =
    \frac{L}{2}\Vert \mathcal x^{(1)} - y^{(1)}\Vert^2 + L 
    \langle x^{(1)} - \bar x, x^{(1)} - y^{(1)}\rangle
    \\
    &= 
    \frac{L}{2}
    (\Vert x^{(1)} - \bar x\Vert^2 - \Vert y^{(1)} - \bar x\Vert^2)
    \\
    \implies
    2L^{-1}\Delta_1 
    &\le
    \underbrace{\Vert y^{(1)} - \bar x\Vert^2}_{=c} - \Vert x^{(1)} - \bar x\Vert^2
    \\
    \implies
    a_1 + b_1
    & \le c
    , 
\end{aligned}
$$

using the fact that $t_1 = 1$ we have $u^{(1)} = x^{(1)} - \bar x \implies b_1 = \Vert x^{(1)} - \bar x\Vert^2$, please observe that the above expression simplifies to $a_1 + b_1 \le c$. Invoking the Third Lemma, we have the claim that $a_{k + 1}\le c$, which is stated as: 

$$
\begin{aligned}
    2L^{-1}t_{k + 1}^2\Delta_{k + 1} 
    &\le \Vert x^{(0)} - \bar x\Vert^2
    \\
    \implies
    \Delta_{k + 1}
    &\le 
    \frac{L\Vert x^{(0)} - \bar x\Vert^2}{2t_k^2}
    \\
    & \le 
    \frac{L\Vert x^{(0)} - \bar x\Vert^2}{2 \times 2^{-2}(k + 1)^2}
    = 
    \frac{2L\Vert x^{(0)} - \bar x\Vert^2}{(k + 1)^2}, 
\end{aligned}
$$

The proof is now complete and the algorithm has strictly better worst case complexity compare to the case where momentum term is not used. 
