<!DOCTYPE html>
    <html>
    <head>
        <meta charset="UTF-8">
        <title>&midast;&midast;Prereq&colon;&midast;&midast;</title>
        <style>
</style>
        <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.10.2/dist/katex.min.css" integrity="sha384-yFRtMMDnQtDRO8rLpMIKrtPCD5jdktao2TV19YiZYWMDkUR5GQZR/NOVTdquEx1j" crossorigin="anonymous">
<link href="https://cdn.jsdelivr.net/npm/katex-copytex@latest/dist/katex-copytex.min.css" rel="stylesheet" type="text/css">
        <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/Microsoft/vscode/extensions/markdown-language-features/media/markdown.css">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/Microsoft/vscode/extensions/markdown-language-features/media/highlight.css">
<style>
            body {
                font-family: -apple-system, BlinkMacSystemFont, 'Segoe WPC', 'Segoe UI', system-ui, 'Ubuntu', 'Droid Sans', sans-serif;
                font-size: 12px;
                line-height: 1;
            }
        </style>
        <style>
.task-list-item { list-style-type: none; } .task-list-item-checkbox { margin-left: -20px; vertical-align: middle; }
</style>
        
        <script src="https://cdn.jsdelivr.net/npm/katex-copytex@latest/dist/katex-copytex.min.js"></script>
        
    </head>
    <body class="vscode-body vscode-light">
        <p>Optimization, especially non-linear optimization</p>
<hr>
<h3 id="prereq"><strong>Prereq:</strong></h3>
<ul>
<li>Linalg</li>
<li>Calculus (Vector Calc)</li>
<li>Helpful: Stats</li>
<li>Helpful: Python</li>
<li>Helpful: Exposure to Optimization</li>
</ul>
<hr>
<h3 id="general-intro-to-the-course"><strong>General Intro to the Course.</strong></h3>
<p>Optimization has 3 legs.</p>
<ol>
<li>Based on the model and the data.</li>
<li>Iterative algorithm development.</li>
<li>Theory and the analysis of the above things.</li>
</ol>
<p>It answers the questions from science that involves some set of observation, and then that is pushed into a minimization problem. We solve that data problem with iterative algorithm. And then we need the theory and analysis to understand the algorithms that are used for the data .</p>
<blockquote>
<p>&quot;Optimization gives us the language we can use to formulate a wide range of problems&quot;</p>
</blockquote>
<p><strong>Frameworks</strong></p>
<ul>
<li>Take all the information about a given problem.
<ul>
<li>Goals</li>
<li>Data</li>
<li>Mechanistic Models</li>
<li>Error Models</li>
<li>Domain Specific Knowledge</li>
</ul>
</li>
<li>Convert all of the above information into a mathematical problem. The problem is phrase in the form of a:</li>
<li>
<blockquote>
<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><munder><mo><mi>min</mi><mo>⁡</mo></mo><mrow><mi>x</mi><mo>∈</mo><mi mathvariant="script">X</mi></mrow></munder><mi>f</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\min_{x\in \mathcal{X}} f(x)
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.521701em;vertical-align:-0.771701em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.66786em;"><span style="top:-2.355669em;margin-left:0em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">x</span><span class="mrel mtight">∈</span><span class="mord mtight"><span class="mord mathcal mtight" style="margin-right:0.14643em;">X</span></span></span></span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span><span class="mop">min</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.771701em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord mathdefault">x</span><span class="mclose">)</span></span></span></span></span></p>
</blockquote>
</li>
</ul>
<p>Where <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">f(x)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord mathdefault">x</span><span class="mclose">)</span></span></span></span> is a function that captures the goals, and the <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi></mrow><annotation encoding="application/x-tex">x</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathdefault">x</span></span></span></span> will be the decision variables that describes the parameters we seek.</p>
<p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="script">X</mi></mrow><annotation encoding="application/x-tex">\mathcal{X}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord"><span class="mord mathcal" style="margin-right:0.14643em;">X</span></span></span></span></span>: Represents the set of feasible domain that the parameters will reside.</p>
<p>The <strong>Challenging</strong> part is the modeling part and the solving part.</p>
<ol>
<li>Making the model for the problem.</li>
<li>Designing the algorithms and understand how they behave for the problem.
<ul>
<li>Converge?</li>
<li>Speed?</li>
<li>Stability?</li>
</ul>
</li>
</ol>
<hr>
<h3 id="course-overview"><strong>Course Overview</strong></h3>
<h4 id="problem-types">Problem Types</h4>
<ul>
<li>Smooth (have derivative)</li>
<li>Non-smooth (Piecewiese Linear like L1 Norm)</li>
<li>Convex Model (Guassian)</li>
<li>Non-Convex (Cauchy)</li>
</ul>
<h4 id="algorithms">Algorithms</h4>
<ul>
<li>Smooth Problems Algorithms:
<ul>
<li>Gradient descent</li>
<li>Newton's method</li>
<li>Wishlist:
<ul>
<li>Gauss-Newton</li>
<li>Quasi-Newton</li>
</ul>
</li>
</ul>
</li>
<li>Non-smooth convex Problems Algorithms:
<ul>
<li>Prox-Gradient</li>
<li>Splitting/ADMM</li>
</ul>
</li>
<li>Non-smooth, non-convex problems algorithms:
<ul>
<li>DAM/PALM</li>
</ul>
</li>
</ul>
<h4 id="theories">Theories:</h4>
<ul>
<li>Convex Analysis:
<ul>
<li>Sets + Functions</li>
</ul>
</li>
<li>Algorithm Analysis:
<ul>
<li>Rate of Convergence</li>
</ul>
</li>
</ul>
<h4 id="modeling-examples">Modeling Examples</h4>
<ul>
<li>Generalized Linear models</li>
<li>Sparsity &amp; related ideas</li>
<li>Low Rank structures in Data</li>
<li>Wishlist:
<ul>
<li>Kalman Smoothing</li>
<li>Trimming &amp; Clustering</li>
</ul>
</li>
</ul>
<hr>
<h3 id="fundamentals"><strong>Fundamentals</strong></h3>
<ul>
<li>
<p>Calculus and Optimality</p>
<ul>
<li>[[Jacobian and Hessian]]</li>
<li>[[Optimality Conditions (Jacobian Hessian)]]</li>
<li>[[Derivatives on Steroids]]</li>
</ul>
</li>
<li>
<p>Functions:</p>
<ul>
<li>[[AMATH 515/Basic Convexity/Convexity]]:
<ul>
<li>Convex Set</li>
<li>Convex Functions</li>
<li>[[Differential Characterization of Convexity]]</li>
</ul>
</li>
<li>Good to optimize functions:
<ul>
<li>[[Closed, Proper, Level Bounded, Strong Convex]]</li>
<li>[[Beta Smoothness]]</li>
</ul>
</li>
<li>Non-Smooth
<ul>
<li>[[Non smooth convex optimization]]</li>
</ul>
</li>
</ul>
</li>
<li>
<p>Algorithms and Analysis:</p>
<ul>
<li>[[Gradient Descend 1]]</li>
<li>[[Gradient Descend 2]]</li>
<li>[[Gradient Descend 3]]</li>
<li>[[Measuring Rate of Convergence]]</li>
<li>[[Proximal Gradient Method]]</li>
<li>[[Proximal Gradient 2]]
Newton's Iterations are the inspirations for Accelerated Gradient Descend.</li>
<li>[[Newton Method]]
Here is an overview:</li>
<li>[[Unconstrained Optimization (Big Overview)]]</li>
<li>[[Steepest Descend for Matrix Vector]]</li>
</ul>
</li>
<li>
<p>Problems</p>
<ul>
<li>[[MLE Robust Fit (Intro)]]</li>
<li>[[Generalized Linear Model]]</li>
</ul>
</li>
</ul>
<p>End of Quarter Theory:</p>
<ul>
<li>Duality: Arise from perturbation theory</li>
<li>[[Duality Preparation]], [[Duality Prepraration 2]]</li>
<li>[[Duality (Dualization)]], [[Duality (Dualitzation More Examples)]], [[Duality (Example Transformation)]]</li>
<li>The Interior Points Method:
<ul>
<li>[[Interior Points]]</li>
</ul>
</li>
</ul>

    </body>
    </html>