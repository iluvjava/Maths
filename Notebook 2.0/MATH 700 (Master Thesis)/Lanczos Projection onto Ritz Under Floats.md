[[Lanczos Algoritm]]
[[Ritz Vectors from Lanczos]]


----
### **Intro**

The orthogonal vectors generated by the Lanczos Algorithm loses orthgonality systematically, proposed by Paige at first, and we are interested in the theory behind the orthgonality of the Lanczos Vector. The proof of the theorem is largely in reference to the Book: \<Applied Numerical Linear Algebra\> by James W.Demmel, in chapter 7. To state the theorem, define the following quantities: 

**Basic Quantities**: 

$$
\begin{aligned}
    T_k &:: \text{Tridiagonal at step k of Lanczos}
    \\
    Q_k &:: \text{Orthogonal matrix at step k of Lanczos}
    \\
    V_k = [v_1\;  v_2\; \cdots \; v_k] &:: \text{Eigen Matrix for } T_k
    \\
    \theta_i &:: \text{the eigenvalues for }v_i, \text{ Ritz Value}
    \\
    \Lambda_k &:: \text{Eigenvalues Matrix for }T_k
    \\
    F &::\text{The floats error matrix from Lanczos Factorizations}
    \\
    \epsilon &:: \text{The machine Epsilon}
\end{aligned}
$$

$\beta_k, \alpha_k$ are the coefficients inside of the Lanczos Tridiaognal Matrix. $Q_k^T T_k Q_k$ will approximates the matrix $A$. Consider the Lanczos Recurrence: 

$$
\begin{aligned}
    AQ_k &= Q_kT_k + \beta_kq_{k + 1}\xi_k^Tv_i
    \\
    AQ_k v_i &= Q_k\theta_iv_i + \beta_k q_{k + 1}(v_i)_k
    \\
    \text{Let: } Q_k v_i &= y_{k,i}
    \\
    Ay_{k, i} &= \theta_i y_{k, i} + \beta_k q_{k + 1}(v_i)_k
\end{aligned}
$$

When, $q_{k + 1}$, representing the case when the krylov subspace is now invariant, the ritz vector $v_i$ is the eigenvector of the matrix $A$. However, our interestes is in about Floating Point Arithematic. 


----
### **Paige's Theorem**

> $$
> \begin{aligned}
>     y_{k, i}^T q_{k + 1} &= \frac{\mathcal{O}(\epsilon \Vert A\Vert)}
>     {
>         \beta_k |(v_i)_k|
>     }
> \end{aligned}
> $$


The projection of the new Lanczos Vector onto the ith ritz vector is inversely proportional to $\beta_k (v_i)_k$, where the multiplier is determined by $\mathcal{O}(\epsilon \Vert A\Vert)$. 


**Proof**

For the sake of simplicity, we ignoer all the subscript goes goes under $Q, T, q,\xi$ and $F$. With subscripts these quantities are $Q_k, q_{k + 1}, T_k, \xi_k, F_k$. 

$$
\begin{aligned}
    AQ &= AT + \beta q\xi^T + F
    \\
    Q^TAQ &= Q^TQT + Q^T\beta q\xi^T + Q^TF
\end{aligned} \tag{1}
$$

Observe that $Q^TAQ$ is symmetric, therefore: 

$$
\begin{aligned}
    Q^TAQ &= (Q^TQT + Q^T\beta q\xi^T + Q^TF)^T
    \\
    &= T^TQ^TQ  + \beta\xi q^T Q + F^TQ
\end{aligned}\tag{2}
$$

Takes the difference between (1), (2), we have: 

$$
\mathbf{0} = (Q^TQT - T^TQ^TQ) + \beta(Q^Tq\xi^T - \xi q^TQ) + (Q^TF - F^TQ)\tag{3}
$$

Consdier the ritz vector and ritz value pairs: $v, \theta$, such that $Tv = \theta v$, and we consider multiplying $v^T, v$ on the left and right of $\beta(\xi q^T Q)$: 

$$
\begin{aligned}
    v^T\beta(\xi q^T Q)v &= \beta(v)_k q^T (Qv)
    \\
    &= \beta(v)_kq^Ty
\end{aligned}\tag{4}
$$

Now, we need to figure out an expresson for the quantity $\xi q^TQ$. **Here, we make the approximation that** $\langle q_i, q_j\rangle = 0$ when $|i - j| \le 2$, in theory, it should be $\mathcal{O}(\epsilon)$, but we assume that the Lanczos orthgonalize exact for the vector $q_{j + 1}$ against the vector $q_j, q_{j - 1}$. **This assumption is made throughout the derivations for the expression**. 

Therefore, we can say that $Q^TQ = I + C^T + C$ where the matrix $C$ is lower triangular with diagonal and sub-diagonals being all zeros, representing the floating points error when the Lanczos Vectors are losing orthogonality. The assumption made above makes the $C$ here to be strictly lower triangular, which means that $C^T + C$ is a matrix with zeros on the tridiagonal parts and all other entires are the floating point errors from Lanczos. 

Simplifying expression (3): 

$$
\begin{aligned}
    Q^TQT - T^TQ^TQ &= (I + C^T + C)T -T^T (I + C^T + C)
    \\
    &= T + C^TT + CT - T^T - T^TC^T - T^TC
    \\
    &= (CT - TC) + (C^TT - TC^T)
\end{aligned}\tag{5}
$$

**Reader Please Observe**

$CT$ is strictly lower triangular, $TC$ is strictly lower triangular as well. This is true because an Tridiagonal matrix only encodes interations between adjacent rows/columns, and $C$ has zeros on it's tridiagonals, therefore, $TC, CT$ gives a matrix that is strictly lower diagonal. 

Therefore, expression (5) can be partitioned into strictly lower and upper triangular matrices. 

**Reader Please Consider**

$\xi q^TQ$, adding back the subscript we have: $\xi_k q_{k + 1}^TQ_k$, observe that $\xi_k q_{k + 1}^T$ is a matrix whose last row is $q_{k + 1}^T$. And because of the way that $q_{k + 1}$ is orthogonalized, the last 2 elements of the last row of $\xi_k q_{k + 1}Q_k$ is zero. <u>Hence it's strictly lower triangular</u>.

**Reader Please Snap out and consider**


$$
\begin{aligned}
    \mathbf{0} &= (Q^TQT - T^TQ^TQ) + \beta(Q^Tq\xi^T - \xi q^TQ) + (Q^TF - F^TQ)
    \\
    \mathbf{0}&= 
    -\underbrace{(CT - TC)}_{\text{strict tril}} + \underbrace{(C^TT - TC^T)}_{\text{strict tril}} + \beta(\underbrace{Q^Tq\xi^T}_{\text{strict triu}} - \underbrace{\xi q^TQ}_{\text{strict tril}}) - (Q^TF - F^TQ)
    \\\implies
    \mathbf{0} &= (CT - TC) - \beta \xi q^TQ + \underbrace{\text{triu}(Q^TF - F^TQ)}_{:= L}
\end{aligned}\tag{6}
$$

Now consider multiplying by $v^T(\bullet)v$ for each terms in the expression and we have: 

$$
\begin{aligned}
    v^T(CT - TC)v &= v^TCTv - v^TTCv
    \\
    &= 
    v^TC\theta v - \theta v^Tcv
    \\
    &= 0
    \\
    \implies 
    v^T\beta\xi q^TQv &= v^TLv
    \\
    (\beta(v)_k)(q^TQv) &= v^T Lv
\end{aligned}\tag{7}
$$

Observe that: 

$$
\begin{aligned}
    |v^TLv| \le \Vert L\Vert &= \mathcal{O}(\Vert Q^TF - F^TQ\Vert)
    \\
    \mathcal{O}(\Vert F\Vert) = \mathcal{O}(\epsilon \Vert A\Vert)
\end{aligned}\tag{8}
$$


I don't know what references support the argument above in (7), but it feels right. (#TODO: CITATION NEEDED) 

$$
\begin{aligned}
    \beta (v)_k &= \frac{\mathcal{O}(\epsilon \Vert A\Vert)}{\beta(v)_k}
    \\
    (Q_kv_i)^Tq_{k + 1} &= \frac{\mathcal{O}(\epsilon \Vert A\Vert)}{\beta(v_i)k}
    \\
    y_{k, i}^Tq_{k + 1} &= \frac{\mathcal{O}(\epsilon \Vert A\Vert)}{\beta(v_i)k}
\end{aligned}\tag{9}
$$

Which completes the proof for the claim. 

---
### **Significant of the Theorem**

It's later, experimented in the papers for the selective orthogonalizations of the Lanczos Algorithm that we see the projection onto the Ritz Vector marks the lost of orthogonality of Lanczos Vectors. 

The Lanczos algorithm forgets that it explored into the direction of well-converged ritz vectors, regenerating $q$ into the same directions, causing $q$ to lose orthogonality. A paper titled \<The Lanczos Algorithm With Selective Orthogonalization\> compat the issues with selective re-orthogonalization and various other tricks to keep track of both, the lost of orthogonality of lanczos vectors, and the converged ritz vectors. 

This is also significant because it uses converged ritz vector to improve stability of the Lanczos. 

---
### **Comments**

[[Cauchy Interlace Theorem]], stated that the eigenvalues of $T_{k}$  are striclty in between $T_{k + 1}$, which implies that, the eigenvalues found for the $T_{k}$ matrix will be changing monotocially, they will have to start somewhere in the middle of the spectrum, and then gradually move to the exterior of the spectrums. 